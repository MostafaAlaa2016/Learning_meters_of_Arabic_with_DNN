  \section{Deep Learning Background}\label{sec_deep_learning_background}

  \textbf{What is Deep Learning?} \textit{ Deep Learning is a new approach of Machine Learning research which focus on learning and understanding from the data without the needs for the human operator to formally specify all the knowledge that the computer needs. This method built using a hierarchy of concept which enables the computer to learn complex concepts by building them layer by layer from simpler ones. If there is a graph which shows how this concept built we will figure out a very deep graph with many layers, for this reason, we call this approach to AI deep learning~\cite{Goodfellow-et-al-2016}}\\

      There was many of early trials to utilize the AI into real life problems. For Example, IBM's Deep Blue chess-playing system which defeated world champion Garry Kasprov in 1997 ( Hsu , 2002 ).%@@@ add the reference
      \\


      Another approach which used to use AI but using hard-code knowledge about the world informal language. A computer can understand statements from the formal language automatically using logical inference rules. This is known as the knowledge base approach to artificial intelligence rules. None of these projects has achieved significant success. For Example, Cyc is tried to gather a comprehensive ontology and knowledge base about the basic concepts about how the world works Cyc  (Lenat and Guha, 1989). Cyc is an inference engine and a database of statements in a language called Cycl. A staff of human supervisors enters these statements. People struggle to devise formal rules with enough complexity to describe the world accurately\cite{Goodfellow-et-al-2016}.\\

      The difficulty faced in the previous system is due to the hard-coded knowledge has shown up the AI need to acquire their knowledge from the data itself. This capability is known as machine learning. This approach has introduced some algorithms which solve and tackle the problems from which we can, for example, check the email is spam or not. Also, it used for other problems for price predictions for housing Example of this algorithms is (Naive Bayes, Logistic regression).

      This simple machine learning approach is working in the data but not with its original format it required some different representation to be input for the model. This different representation named feature engineering. Feature Engineering example: in case of email spam or not spam example it can be word frequency, char frequency, class attributes, capital letters frequency, some other data processing such as remove stop words from the input lemmatization. So, all the previous feature provided by a human expert which know the problem in details and analyzing which features it affect the data then add it as a feature to the input model.
      \newpage

      However, for many tasks, it is difficult to identify the features which should be extracted. For example, we need to detect cars in photographs. We know every car have wheels. So, to detect cars, we can check if there is a wheel to be a feature for car detection. However, to detect or to describe wheels in terms of pixel values is a difficult task. The image may be not clear or may be complicated by shadows, the sun glaring off the metal parts of the wheel, the blurring in images may not make it clear sometimes, and so on\cite{Goodfellow-et-al-2016}.\\

      One solution to solve this problem is to use machine learning itself to discover not only the output of the model but also the features which are the input for the model. This approach is known as representation learning. Learned representation can achieve better results than hard-designed representation. This approach also allows AI systems to rapidly adapt to new tasks or be automatically identify it from any new data. A representation learning can discover many features automatically fast or can take more times in case complex tasks, but at least it will get an excellent set of features which adapt for any complex problem without the need for manual features. In this research, we used the AI to identify the features for our model which make this model get a breakthrough results than the old fashion of manual feature machine learning used.

      If we go back to the image example, we can show that it is not an easy task to extract features to detect the car from an image. So, Deep learning is trying to solve this problem in feature engineering by introducing representation learning that are build complex representations in terms of another simpler layer of representations Figure~\ref{fig:DeepLearningImagePersonExample.png} shows how deep learning represents an image of a person by combining simpler representation example the edges and contours which led to understanding complex representations. The benefit from allowing the computer to understand the data and building the representation is the ability now for building and understanding very complex representation and also, to utilize and combine features from simpler to deep representations with many ways such as recurrent or sequences.

      
Modern deep learning provides a compelling framework for learning data problems. This model becomes more complex by the adding more layers and more units within a layer. Deep Learning model is working perfectly on the big dataset which allows the model to learn the data features in a good way.


In the remaining parts in this section we will start introducing the main concepts and component used in deep learning, Also the basic unit into Recurrent Neural networks and LSTM.

      
\begin{figure}[ht!] \includegraphics[width=\linewidth]{./Figures/Ch_2_Background/DeepLearningImagePersonExample.png}
  \caption{Illustrations on how can Deep Learning work based on images figure presented from~\cite{Goodfellow-et-al-2016}~\cite{Zeiler2014}.}
  \label{fig:DeepLearningImagePersonExample.png}
\end{figure}


\newpage
\subsection{Logistic Regression}
Logistic Regression is a machine learning algorithm which we can assume has the basic idea behind the deep learning we will explain it later. Also, Logistic Regression is one of the most used machine learning techniques for binary classification.

A simple example of logistic regression it would be if we have an algorithm for fraud detection. It takes some raw data input and detect if it is a fraud case or not let’s assume fraud case is one and a non-fraud case is zero. David Cox developed logistic regression in 1958~\cite{Cox2958}. The logistic name came from its core function logistic function which also named as \textit{Sigmoid function}  function~\eqref{eq:logistic_function}. The Logistic function is shaped as S-shape.

Also, one of these function features it can take any input real number and convert it into a value between 1 and 0.
\input{Figures/Ch_2_Background/fig_logistic.tex}


Let's take an Example, Given x, we want to get the predictions of $\widehat{y}$ which is the estimate of $y$  when $\widehat{y}$  is presented in equation~\eqref{eq:yhat_estimate}. So,to calculate the output function for logistic regression using equation~\eqref{eq:logistic_regression_yhat}. Note: if we remove the Sigmoid function $\sigma$ from the equation it will be Linear Regression model and $\widehat{y}$ can be greater than 1 or negative. Figure~\ref{fig:logistic} show the Sigmoid function output. 

\begin{equation}\label{eq:logistic_function}
  x = \frac{1}{1-e^{-x}} \quad \text{where} \quad x \in \mathbb{R}^{n_x} 
\end{equation}

\begin{equation}
  \label{eq:yhat_estimate}
    \widehat{y} = P(y=1 | x) \quad \text{where}  \quad 0 \le \widehat{y}  \le 1
  \end{equation}

\begin{equation}
  \label{eq:logistic_regression_yhat}
  \widehat{y} = \sigma(w^t x + b)  \quad \text{where:} \quad  \sigma(z) = \frac{1}{1-e^{-z}} \text{, }  w \in  \mathbb{R}^{n_x} \text{, }  b \in  \mathbb{R}  
\end{equation}


\subsubsection{Loss Error Function}

Loss Error Function is the function which describes how well our algorithm can understand  $\widehat{y}$ y b when the true label is y. It also can be defined as the difference between the true value of $y$ and the estimated value of  $\widehat{y}$.~\footnote{\textit{Parts of this subsections are explained into Andrew NG Coursera courses in deep learning and It written using our understanding to this topic but the equations and the idea taken from the course  https://www.coursera.org/learn/neural-networks-deep-learning/}}. Equation~\eqref{eq:loss function} describe the loss function for Logistic Regression. There are another functions can represent the loss functions but we take the below as example. As we know $y$ is the label which should be 1 or 0. So, The reason why this function make sense to describe the loss function as below
\begin{itemize}
\item in case (y = 1) equation~\eqref{eq:loss_function_log_y_1} we need $\widehat{y}$ to be big as possible to be equal or near y true which is 1. So, $ - (\log \widehat{y} )$ will get the value. Note as explained before Sigmoid function can't be greater than 1 or less than 0. %@@@ add chart here to explain
\item in case (y = 0) equation~\eqref{eq:loss_function_log_y_0} we need $\widehat{y}$ to be small as possible to be equal or near y true which is 0. So, $- \log (1-\widehat{y})$  will get the value.  %@@@ add chart here to explain
  \end{itemize}
  
\begin{equation}
  \label{eq:loss function}
    \ell(y,\widehat{y}) = - (y \log \widehat{y} + (1-y) \log (1-\widehat{y}))
  \end{equation}

\begin{equation} \label{eq:loss_function_log_y_1}
\begin{split}
  \text{(if y = 1) } \quad  \ell(y,\widehat{y}) & = - (y \log \widehat{y} + (1-y) \log (1-\widehat{y})) \\
  & = - (1 \log \widehat{y} + (1-1) \log (1-\widehat{y}))\\
  & = - (\log \widehat{y} )
\end{split}
\end{equation}


\begin{equation} \label{eq:loss_function_log_y_0}
\begin{split}
  \text{(if y = 0) } \quad  \ell(y,\widehat{y}) & = - (y \log \widehat{y} + (1-y) \log (1-\widehat{y})) \\
  & = - (0 * \log \widehat{y} + (1-0) \log (1-\widehat{y}))\\
  & = - \log (1-\widehat{y})
\end{split}
\end{equation}




\subsubsection{Cost Function}
    To predict $y$ from $\widehat{y}$ we learn from the input parameters in this case it will be \textbf{\textit{(w,b)}} from Equation~\eqref{eq:logistic_regression_yhat} as  \textbf{\textit{(w,b)}} is the parameters which define the relation between input dataset X and the output Y. So, Cost Function will measure how well you are doing an entire training set and the ability to understand the relation between X,Y.

Cost function \textbf{\textit{J}} in equation~\eqref{eq:cost_function} is the average of loss function applied to every training example which equal the sum of the lost for each training example divided on the total number of training example.



\begin{equation}\label{eq:cost_function}
  \begin{split}
  J(w,b) & = \frac{\sum_{i=1}^{m}  \ell(y^i,\widehat{y^i})}{m} \quad \text{ where m is the total number of training example} \\
  & = \frac {- \sum_{i=1}^{m} [(y^i \log \widehat{y^i} + (1-y^i) \log (1-\widehat{y^i}))]}{m}  
  \end{split}
\end{equation}


\subsubsection{Convex Function vs Non-Convex Function }

\newpage
\subsubsection{Gradient Descent}

As we explained in the previous parts, we need to find the relation between X,Y from the input parameters \textbf{\textit{(w,b)}} which will make the cost function ~\eqref{eq:cost_function} to the minimum. In other words we need to find the best value of \textbf{\textit{J(w,b)}} which will represent the relation and reduce the error between $y$ and $\widehat{y}$  So, we need to minimize \textbf{\textit{J(w,b)}}. 
\input{Figures/Ch_2_Background/fig_gradient_decent.tex}



To illustrate the relation between \textbf{\textit{J(w,b)}} we will assume for simplicity the relation will be function of one variable \textbf{\textit{J(w)}}. As shown in Figure~\ref{fig:gradient_decent_surf} we have a curve which represent the function \textbf{\textit{J(w)}} we need to find the minimum point in this curve which is the local minimum (red point in the previous figure) assuming it is a  \textbf{\textit{convex function}}. We will use equation~\eqref{eq:gredient_descent_w} to find the local minimum.

To explain how this equation works let's take simple function $f(x) = x^2$ then select a random point $P_1$ from Figure~\ref{fig:derivative_example} then pick another point $P_2$ let's take derivative \textit{(which by definition is the slope of the function at the point which also the change between these two points)} The slope of this function is the height (3) divided by the width (1) this is the tangent of $J(w)=\frac{3}{1}$ at this point. If the derivative is positive so, w will be update minus the derivative multiplied by learning rate alpha $\alpha$ as~\eqref{eq:gredient_descent_w}. We will repeat the previous step until value of w get the lowest minimum. When w get the lowest minimum the derivative will be negative so, w will start to increase again at this step the algorithm will stop. Also, we can demonstrate the effect of different $\alpha$ values and its impact on the function we can show this effect in Figure~\ref{fig:alpha_change} but the main point it is not always a happy scenario sometimes the high $alpha$ is not a good idea, and it depends on the problem and the dataset.


\begin{figure}[!h]
\begin{center}
\input{Figures/Ch_2_Background/fig_derivative_example.tex}
\caption{Derivative Example of function $f(x) = x^2$ }\label{fig:derivative_example}
\end{center}
\end{figure} 


\begin{equation}\label{eq:gredient_descent_w}
  \begin{split}
    w & := w - \alpha dw \quad \text{\textit{alpha is learning rate}}\\
      & := w - \alpha \frac{dJ(w)}{dw} \quad \text{\textit{d represent the derivative wrt w}}
  \end{split}
\end{equation}

\begin{subequations}
     \begin{align}
w& := w - \alpha \frac{dJ(w,b)}{dw} \label{eq:gradient_descent_j_w}\\
b& := b - \alpha \frac{dJ(w,b)}{db} \label{eq:gradient_descent_j_b}
     \end{align}
   \end{subequations}

\newpage
Now, Let's generalize the above equation assume we have two parameters  \textbf{\textit{(w,b)}} and we need to calculate the cost function for  \textbf{\textit{J(w,b)}} we will work on as two steps first function~\eqref{eq:gradient_descent_j_w}  wrt \textbf{\textit{(w)}} and second function~\eqref{eq:gradient_descent_j_b} wrt \textbf{\textit{(b)}}

%\begin{equation}\label{eq:gradient_descent_j_w}       w := w - \alpha \frac{dJ(w,b)}{dw}  \end{equation}

%\begin{equation}\label{eq:gradient_descent_j_b}      b := b - \alpha \frac{dJ(w,b)}{db}  \end{equation}


\begin{figure}[!h]
\begin{center}
\input{Figures/Ch_2_Background/fig_derivative_alpha_change.tex}
\caption{Derivative Example of function  $f(x) = x^2$ where $\alpha_1$ > $\alpha_2$}\label{fig:alpha_change}
\end{center}
\end{figure} 


\newpage
  \subsubsection{Logistic Regression derivatives}\label{logistic_bp_derivatives}

  As described we need to calculate the gradient descent to get the best $\widehat{y}$ which minimizes the total cost in equation~\eqref{eq:logistic_regression_derivatives_single_example}. So, we will do backpropagation to get the value of $dz$ we need to calculate $da$ in equation~\eqref{eq:logistic_regression_derivatives_da} then we will calculate $dz$ based on the output of $da$ from equation~\eqref{eq:logistic_regression_derivatives_dz}. After that, We will start to take the derivative for $z$ function parameters \textbf{\textit{$w_1,w_2,b$}}. Once we got the values of \textbf{\textit{$dw_1,dw_2,db$}} we can use it to calculate the estimated values of \textbf{\textit{$w_1,w_2,b$}} in the equations~\eqref{eq:logistic_regression_derivatives_dw1},~\eqref{eq:logistic_regression_derivatives_dw2},~\eqref{eq:logistic_regression_derivatives_db}

\begin{equation}\label{eq:logistic_regression_derivatives_single_example}
    \boxed{\widehat{y} = \sigma(z) = a} \longrightarrow  \boxed{ z = w^tx + b = w_1x_1+ w_2+x_2+ b} \longrightarrow \boxed{\ell(a,y)}
  \end{equation}
  \begin{equation}\label{eq:logistic_regression_derivatives_da}
      \boxed{da =  \frac{d\ell}{da} = \frac{d\ell(a,y)}{da} = - \frac{y}{a} + \frac{1-y}{1-a}}
  \end{equation}
    \begin{equation}\label{eq:logistic_regression_derivatives_dz}
    \boxed{dz = \frac{d\ell}{dz} =  \frac{d\ell(a,y)}{dz} =  \frac{d\ell}{da} .  \frac{da}{dz}} = \boxed{(- \frac{y}{a} + \frac{1-y}{1-a}) . a(a-1) } = \boxed{ a - y    }
  \end{equation}
 \begin{equation}\label{eq:logistic_regression_derivatives_dw1}
      \boxed{dw_1 = \frac{\partial\ell}{dw_1} = x_1 dz} \longrightarrow \boxed{ w_1 := w_1 - \alpha dw_1}
  \end{equation}
    \begin{equation}\label{eq:logistic_regression_derivatives_dw2}
    \boxed{dw_2 = \frac{\partial\ell}{dw_2} = x_2 dz} \longrightarrow \boxed{ w_2 := w_2  - \alpha dw_2}
  \end{equation}


  \begin{equation}\label{eq:logistic_regression_derivatives_db}
    \boxed{db = \frac{\partial\ell}{db} =  dz} \longrightarrow \boxed{ b := b - \alpha db}
\end{equation}


% \begin{align*}
% \tcbhighmath[remember as=fx]{f(x)} &= xx \text{dummy function for testing} \\
% %&= -\frac{1}{x} + \frac{1}{1}\\
% &=
% \tcbhighmath[remember,overlay={%
% \draw[blue,very thick,->] (fx.south) to[bend right] ([yshift=1mm]frame.west);}]
% {1-\frac{1}{x}.}
% \end{align*}
 \subsubsection{Implementing Logistic Regression on m example}

To implement a simple 1 iteration example below sample code simulate the program structure. First,  assume $J = 0, dw_1 = 0, dw_2 = 0,db = 0$. Then calculate the feedforward step. Then backpropagation calculate. Finally, update the parameters. We can transfer the above equation into the below python sample code. 
%%, caption=Simple Implementation for 1 iteration Logistic Regression with a Neural Network
 \begin{lstlisting}[language=Python]
   import numpy as np
   J = 0, dw_1 = 0, dw_2 = 0,db = 0, alpha = .02
   # FEED FORWARD PROPAGATION
   A = 1 / (1 + np.exp(-(np.dot(w.T,X) + b))#   Z = np.dot(w.T,X) + b
   cost = (- 1 / m) * np.sum(Y * np.log(A) + (1 - Y) * (np.log(1 - A)))
   # BACKWARD PROPAGATION (TO FIND GRADIENT)
   dw = (1 / m) * np.dot(X, (A - Y).T) #    dz = A - Y
   db = (1 / m) * np.sum(A - Y)
   # UPDATE THE PARAMETERS
   w = w - alpha * dw
   b = b - alpha * db
 \end{lstlisting}

\newpage 
 \subsection{The Neuron}

 As we all know, Most computer research is trying to simulate the human brain as it is the most advanced smartest creation. If we are trying to check how the model understands the new information regarding for example bananas photo we can give a baby two bananas then ask him about it baby can remember it with all it new shapes. Same case if you inform any human about some information and trying to get a new inference it will automatically detect this information. So, The new research trying to simulate the human brain model into an Artificial Intelligence model to trying to get this performance. In this subsection, we will try to give an overview of the relation between the new research era and the human brain.
 
 The neuron is the foundation unit of the brain. The size of the brain is as about the size of a grain of rice. The brain contains more over 10000 neurons with average 6000 connections with other neurons\footnote{\textit{Restak, Richard M. and David Grubin. The Secret Life of the Brain. Joseph Henry Press, 2001.}}.  These massive networks allow our brain to build its knowledge about the world around us. The neuron is work by receiving the information from other neuron and process it uniquely then pass the output to other neurons this process is shown in figure~\ref{fig:NeuronStructure}.

 \begin{figure}[ht!] \includegraphics[width=\linewidth]{./Figures/Ch_2_Background/neuron_structure.png}
  \caption{Description of neuron's structure this figure from~\cite{DLFundamentals}}
  \label{fig:NeuronStructure}
\end{figure}

 
 How do we learn a new concept? \textit{The neuron receives its input from dendrites. The incoming neuron connection is dynamically strengthened or weakened based on how often it is used, and the strength of each connection determines the contribution of the input to the neuron's output. Based on the connection strength it will have weight then the input is summed in the cell body. This sum is transformed into a new signal which is propagated along the cell's axon and sent to other neurons\cite{DLFundamentals}}.

 The above biological model can be translated into an Artificial Neural Network as described in figure XXXX. %@@@ add figure for neuron input format here
 We have an input $x_1,x_2,x_3,...,x_n$ every input has its own strength (weight) $w_1,w_2,w_3,...,w_n$. We Sum the multiplication of X and W to get the logit of the neuron, $z =  \sum_{i=0}^{n} x_i w_i $. The logit is passed throw a function $f$ to produce the output $ y = f(z)$ the output will be the input to other neurons. Note: In many cases, the logit can also include a bias constant. So, in this case the function will be $$ y = f(\sum_{i=0}^{n} x_i w_i + b)$$
 
 \subsection{The Neural Network Representation}
 As explained previously, We have been trying to simulate the human brain model into our research work in Deep Neural Network. So, We will have multi-layers to allows the model to get in-depth knowledge and more computation performance to simulate the human brain.

 Now, we will represent the functions per layer as below equations where \textit{l is refer to layer number, i refer to the node number in the layer}\eqref{eq:nn_multi_layer}
 
\begin{equation}\label{eq:nn_multi_layer}
  \boxed{z^l =  W^l x + b^l} \longrightarrow \boxed{a_i^l =  \sigma(z^l)} \longrightarrow \boxed{\ell(a^l,y)}
\end{equation}

What is the Neural Networks component?

\textbf{Input Layer:} Input layers is the input data raw for the network it is denoted as $a^0$.
\textbf{Hidden Layers:} The layers between the input layers and the output layer it can be any number of layers. It also has a set of weighted input and produces an output through an activation function. Every layer in the hidden layer transmits the output to the other hidden layer as an input feature figure XXXX shows this relations. %@@@ NN representation

\textbf{Output Layer:} It is one output layer with have the final results from the hidden layers.

 \subsection{Neural Network Computation}
 In this subsection, We will show as example on how we can compute the Neural Networks for every layer. In figure XXXX we have example of one layer we will continue explain on this example\eqref{eq_nn_one_layer}.

 \begin{subequations}\label{eq_nn_one_layer}
   \begin{align}
     Z_1^{[1]} & = w_1^{[1]T} x + b_1^{[1]} , a_1^{[1]} = \sigma(Z_1^{[1]}) \\
     Z_2^{[1]} & = w_2^{[1]T} x + b_2^{[1]} , a_2^{[1]} = \sigma(Z_2^{[1]})\\
     Z_3^{[1]} & = w_3^{[1]T} x + b_3^{[1]} , a_3^{[1]} = \sigma(Z_3^{[1]})\\
     Z_4^{[1]} & = w_4^{[1]T} x + b_4^{[1]} , a_4^{[1]} = \sigma(Z_4^{[1]})
 \end{align}
\end{subequations}
If we need to compute the above equations it will be simply be represented as vectorized way below matrix shows how we can implement it.
\[
z^{[1]} = 
\left[
  \begin{array}{ccc}
     w^{[1]T}_{1} \\
     w^{[1]T}_{2} \\
     w^{[1]T}_{3} \\
     w^{[1]T}_{4} \\  
  \end{array}
\right]\cdot
\left[
  \begin{array}{c}
           x_{1} \\
           x_{2} \\
    x_{3} %\vdots \\
  \end{array}
\right] +
\left[
  \begin{array}{c}
           b_{1}^{[1]}\\
           b_{2}^{[1]}\\
           b_{3}^{[1]}\\
           b_{4}^{[1]}
  \end{array}
\right] =
\left[
  \begin{array}{cccc}
     w^{[1]T}_{1} x + b _1^{[1]}\\
     w^{[1]T}_{2} x + b _2^{[1] }\\
     w^{[1]T}_{3} x + b _3^{[1] }\\
     w^{[1]T}_{4} x + b _4^{[1] }\\  
  \end{array}
\right] =
\left[
  \begin{array}{c}
    z_1^{[1]} \\
    z_2^{[1]} \\
    z_3^{[1]} \\
    z_3^{[1]}
  \end{array}
\right]
\]

\newpage
\subsubsection{Linear Neurons and Their Limitations}

Now, We explained the equations for the feedforward Neural Network. We have only one point we need to discuss it which is the Activation function. Let's assume we will continue use linear function~\ref{fig:linear} $y= w x + b$. So, if we have mutli-layer networks for example equation~\eqref{eq_linear_fun_limitations} it will end as linear function because composition of two linear function will be linear function. So, we will not compute deep computation and we will get limited information from the networks. So, to be able to detect the deep information we will use different function for the hidden layers example: Tanh Figure~\ref{fig:tanh} and Equation~\eqref{eq:nn_tanh}, Sigmoid Figure~\ref{fig:sigmoid} and  Equation~\eqref{eq:logistic_function} and Relu Figure~\ref{fig:relu} Equation~\eqref{eq:nn_relu}. Most of binary classification problems use Sigmoid function for output layer. Also, we can use the same functions for the output but we can also use the linear for activation function in some cases.



\begin{figure}[ht!]
  \centering
  \subfigure[RELU activation function.]{\label{fig:relu}
            \begin{tikzpicture}
              \input{Figures/Ch_2_Background/fig_relu.tex}
            \end{tikzpicture}}
%
  \subfigure[Tanh activation function.]{\label{fig:tanh}
            \begin{tikzpicture}
              \input{Figures/Ch_2_Background/fig_tanh}
            \end{tikzpicture}}
%          
\subfigure[Linear activation function.]{\label{fig:linear}
            \begin{tikzpicture}
              \input{Figures/Ch_2_Background/fig_linear_fun.tex}
            \end{tikzpicture}}
%
\subfigure[Logistic sigmoid activation function.]{\label{fig:sigmoid}
            \begin{tikzpicture}
              \input{Figures/Ch_2_Background/fig_sigmoid.tex}
            \end{tikzpicture}}
          \caption{Common used activation functions include the logistic sigmoid $\sigma(z)$, the hyperbolic tangent $\tanh(z)$, the rectified hyperbolic tangent RelU $Relu(x)$, and linear function.}

\end{figure}

%@@@@@@@@@@@@@fix figure load time


\begin{subequations}\label{eq_linear_fun_limitations}
   \begin{align}
     Z^{[1]} & = w_1^{[1]T} x + b_1^{[1]} , a_1^{[1]} = \sigma(Z_1^{[1]}) \\
     Z^{[2]} & = w^{[2]T} a^1 + b^{[2]} = w^{[2]T} (w^{[1]T}x + b^{[1]}) + b^{[2]}\\
             & = (w^{[1]T}W^{[2]T})x + (w^{[2]}b^{[1]}+ b^{[2]})\\
             & = W' x + b'
\end{align}
\end{subequations}



 
\begin{equation}\label{eq:nn_tanh}
  a = tanh(z) =\frac{e^z-e^{-z}}{e^z+e^{-z}}
\end{equation}%@@@ add figure for tanh



\begin{equation}\label{eq:nn_relu}
  a = max (0,z)
\end{equation}%@@@ add figure for relu

\subsubsection{Softmax Output Layers}
Sometimes our problem has multi-output results not only 1 or 0. For example, we have a problem to recognize the characters from 0 to 9 in MNIST dataset, But we will not be able to recognize digits with 100\% confidence. So, we will use the probability distribution to give us a better idea of how confident we are in our predictions. The result will be an output vector of the form of the $\sum_{i = 0}^9P_i=1$

This is achieved by using a special output layer named softmax layer. This layer is differ from the other as the output of a neuron in a softmax layer is depending on the output of all the other neurons in its layer. This because its sum of all output equal 1. If we assume $z_i$ be the logit of $i^{th}$ softmax neuron, we can normalize by setting its output to represented from eq~\eqref{eq:nn_softmax_fun}:

\begin{equation}\label{eq:nn_softmax_fun}
  y_i=\frac{e^{z_i}}{\sum_je^{z_j}}
\end{equation}

The strong prediction will have a value entry in the vector close to 1, while the other entries will be close to 0. The weak prediction will have multiple possible labels has almost the equal values\cite{DLFundamentals}.



\subsubsection{Forward-Propagation in a Neural Networks}
%@@@ add figure to show the network example similar https://www.coursera.org/learn/neural-networks-deep-learning/lecture/MijzH/forward-propagation-in-a-deep-network
We will take the below figure XXXX as example of Deep Neural Network. So, to calculate the Forward propagation we will follow the below equation~\eqref{eq_feedfarward_DL}. Note: we assume $X = a^{[0]}$ as initial function notation. Also, $\widehat{Y}= g(Z^{[4]}=A^{[4]}$ as the final output layer.
\begin{equation}\label{eq_feedfarward_DL}
     Z^{[l]}  = w^{[l]} a^{l-1} + b^{[l]} , A^{[1]} = g^{l}(Z^{[l]})
   \end{equation}
   % @@@ figure to show the input forward and back propagation steps



\subsubsection{Back-Propagation in a Neural Networks}

We explained previously,  how neural networks could learn their weights using gradient descent algorithm. In this part, we will explain how to compute the gradient of the cost function.

To compute the gradient descent in Neural Networks, we use an algorithm named \textit{backpropagation}. The backpropagation algorithm was initially invented in the 1970s, but it wasn't shining until one of the most important papers in this field published in 1986 %@@@cite https://www.nature.com/articles/323533a0
which describes several neural networks where backpropagation has a significant performance better than the earlier approaches and making it possible to use neural networks to solve problems which were previously not possible to be solved. Now, the backpropagation is the backbone for the learning in neural networks.%@@@cite Michael A. Nielsen, "Neural Networks and Deep Learning", Determination Press, 2015

The backpropagation not only an algorithm which gives us the expression for partial derivative of the cost function $C$ with respect to wights $w$ and bias $b$ but also it gives is an intuations about the change of the cost function while changing its variables $w \& b$ and its effect to the overall network.

As explained in logistic regression section (\ref{logistic_bp_derivatives}) how we can calculate the derivatives for logistic regression with one layer using this equations\eqref{eq:logistic_regression_derivatives_single_example},\eqref{eq:logistic_regression_derivatives_da},\eqref{eq:logistic_regression_derivatives_dz},\\
\eqref{eq:logistic_regression_derivatives_dw1},\eqref{eq:logistic_regression_derivatives_dw2},\eqref{eq:logistic_regression_derivatives_db}.\\
We will generalize the derivatives equations to be for $l$ layers from the below equations\eqref{eq_nn_bp_l_layers}.
 \begin{subequations}\label{eq_nn_bp_l_layers}
   \begin{align}
     dz^{[l]} & = da^{[l]} * g^{[l]'}(z^{l}) \\
     dw^{[l]} & = dz^{[l]} \cdot a^{[l-1]} \\
     db^{[l]} & = dz^{[l]} \\
     da^{[l-1]} & = W^{[l]T} \cdot dz^{[l]} %\\
%     dz^{[l]} & =  (W^{[l+1]T} \cdot dz^{[l+1]}) * g^{[l]'}(z^{l}) \quad \text{from 2.24d in 2.24a}
 \end{align}
\end{subequations}
We can vectorize the above equation for Neural Network implementation as below equations\eqref{eq_nn_bp_l_layers_vectorize}.
 \begin{subequations}\label{eq_nn_bp_l_layers_vectorize}
   \begin{align}
     dz^{[l]} & = dA^{[l]} * g^{[l]'}(z^{l}) \\
     dw^{[l]} & = \frac{1}{m} dz^{[l]} \cdot A^{[l-1]T} \\
     db^{[l]} & = \frac{1}{m} \text{ np.sum(}dz^{[l]}\text{,axis=1,keepdims = true)} \\
     dA^{[l-1]} & = W^{[l]T} \cdot dz^{[l]} %\\
%     dz^{[l]} & =  (W^{[l+1]T} \cdot dz^{[l+1]}) * g^{[l]'}(z^{l}) \quad \text{from 2.24d in 2.24a}
 \end{align}
\end{subequations}

If we checked the input variable in the backpropagation we will find it is $da^{l}$ and this is the derivative of~\eqref{eq:loss function} which we can get it as explained previously from~\eqref{eq:logistic_regression_derivatives_da} this is the formula for final layer in the feedforward step. If we need to calculate the vectorize version of this equation we can use equation\eqref{eq:logistic_regression_derivatives_da_vectorize}

 \begin{equation}\label{eq:logistic_regression_derivatives_da_vectorize}
      da =  \frac{d\ell}{da} = \frac{d\ell(a,y)}{da} = (- \frac{y^{[1]}}{a^{[1]}} + \frac{1-y^{[1]}}{1-a^{[1]}} \ldots - \frac{y^{[m]}}{a^{[m]}} + \frac{1-y^{[m]}}{1-a^{[m]}} )
  \end{equation}
   
\newpage
\subsubsection{How we Initialize the Wights}

    As we explained previously in Logistic regression, We initialized the weights to Zero. However, in Deep Neural Networks it will not work. Note: It is okay to initialize the Bias to Zero but the wights it will not works. Let's see what will happen if we initialize the weights and Bias to Zero.
 
  % @@@https://www.coursera.org/learn/neural-networks-deep-learning/lecture/XtFPI/random-initialization figure
  Assume from figure XXXX we have two input vectors $x_1,X_2$ if we initialize $W^{[1]}$ to Zero from equation\eqref{eq:nn_weights_init_zero} and $b^{[1]}$ to Zeros. So, $a_1^{[1]}=a_2^{[1]}$ because both of the hidden units compute the same functions. Also, $W^{[2]}=[0 0]$ Then when we will compute the backpropagation we will find that $dz_1^{[1]}=dz_2^{[2]}$. So, After every iteration, we will find that the two hidden units calculate the same function and we will not get more information from this Deep Neural Network. We need to highlight that the main idea from Neural Networks as explained before is every hidden unit should work to get a new piece of information. The more hidden unit, the more hidden information we will get but if we initialize it to Zero. It will be the same function which is calculated, and we will not get any new information\footnote{\textit{Parts of this subsection are explained into Andrew NG Coursera course in deep learning and It written using our understanding to this topic but the equations and the idea taken from the course  https://www.coursera.org/learn/neural-networks-deep-learning/}}.

\begin{subequations}\label{eq:nn_weights_init_zero}
\begin{align}
  W^{[1]} = \begin{bmatrix} 0 & 0\\ 0 & 0 \end{bmatrix} \quad b^{[1]} = \begin{bmatrix} 0 \\ 0 \end{bmatrix} \\
  W^{[2]} = \begin{bmatrix} 0 & 0 \end{bmatrix} \\
  a_1^{[1]} = a_2^{[1]} \quad     dz_1^{[1]} = dz_2^{[1]}\\
  dw = \begin{bmatrix} u & u \\ v & v \end{bmatrix} \quad W^{[1]} = W^{[1]} - \alpha dw
\end{align}
\end{subequations}
     
To initialize weights and to get the maximum value of the neural network computation we should initialize the weight by any small random numbers to avoid the big weights which will tend to get the small slope from the Z where $Z^{[1]}= W^{[1]} X + b^{[1]}$ For example, if we use tanh we will get the big tail values $a^{[1]}= g^{[1]}(Z^{[1]})$. So, the big weights we more likely to get slow learning rate. 
  
%@@@$\subsubsection{Deep Learning Running Cycle}
%@@@@ Cost function vs Loss Function vs Gradient Desend 

\newpage
\subsection{Recurrent Neural Networks (RNNs)}\label{sec_RNN}

Deep Neural Networks shows its ability to solve many problems. However, in some use cases, Naive Neural Network architecture cannot works or get the expected results. One of the famous example related to this issue in the NLP tasks when working on a text problem for example, If we say our Harry is the king and Elizabeth is the queen, and we need our model to understand from the sentence that, Harry is he and Elizabeth is she. Also, if this word appears again, we need the model to detect that Harry is a person.

This type of problem has a dependency on the input text and how to get the output prediction based on the provided information from the input.

As explained previously, Most of the research in this area trying to simulate human brains. So, we will not find anyone every time trying to think about something start from scratch it always starts from another related point. Example, What is the human do if he tries to connect the information to generate the knowledge about something.

RNN shows its ability to work on sequence data and its related application problems such as natural language\cite{Mikolov_et_al}. showed the effective of RNN on language modeling. There are many problems which based on this idea of dependency. For example,
\begin{itemize}
\item Time series anomaly detection.
\item Speech recognition.
\item Music Composition.
\item Image captioning.
\item Stock market prediction.
\item Translation.
\end{itemize}
So, What are the problems in the Naive Neural Network architecture?
\begin{itemize}
\item Input and output length can be the different length in a different example.
\item The most important issue is that the Naive architecture cannot share features learned across different positions of text. In this case, we will lose the learned feature, and the lake of dependency, in this case, will affect the overall performance.
\end{itemize}
What is the new proposed architecture which can provide a way to share the features between the Network?
\begin{itemize}
\item First, Assume we have input features $x_1, x_2, x_n$ in the old architecture we input all these features to the Neural Network but now we will input for example $x_1$ and take the output activation from $a^{<1>}$ to be a feature input with $x_2$ then take the output activation from $a^{<2>}$ as input to $x_3$ similar till $x_n$ figure~\ref{fig:RNN-rolled-loop} shows an example. So, This new change will allow us to share the learned feature between the networks input data. Also, we can thing about it as multiple copies of the same network, each passing a message to a successor\cite{colah}.

%   \begin{figure}[ht!] \includegraphics[width=\linewidth]{./Figures/Ch_2_Background/RNN-unrolled.png}
%  \caption{Recurrent Neural Networks Loops\cite{colah}}
%  \label{fig:RNN-rolled-loop.png}
%\end{figure}

\begin{figure}[ht!]
  \input{./Figures/Ch_2_Background/Fig_RNN_unrolled.tex}
  \caption{Recurrent Neural Networks Loops\cite{colah}}\label{fig:RNN-rolled-loop}
\end{figure}

%\begin{figure}[ht!] %\includegraphics[width=\linewidth]{./Figures/Ch_2_Background/andew_ng_feedfarward.png}
%  \caption{Recurrent Neural Networks feedfarward \textit{ This figure from Andrew NG course sequence models https://www.coursera.org/learn/nlp-sequence-models/ }}
%  \label{fig:andew_ng_feedfarward}
%\end{figure}
% @@@ to be replaced by new owned ones

% @@@add example about the new architecture

\item Second, The feedfarward will be compute for time t and then we will calculate the loss at step t. The final loss is the sum of loss at every step t eq\eqref{eq:rnn_feedfarward} explains the steps for feedfarward. Note: The backpropagation here will be calculated though time at every step.
%@@@ change the notations from Andrew to Blog
  \begin{subequations}\label{eq:rnn_feedfarward}
\begin{align}
  a^{<t>} & = g(W_{aa}a^{<t-1>}+ W_{ax}x^{<t>}+b_a)\\
   & = g(W_a[a^{<t-1>},x^{<t>}]+ b_a)\\
  \widehat{y}^{<t>} & = g(W_{ya}a^{<t>}+ b_y)
  \\ \ell^{<t>}(\widehat{y}^{<t>},y^{<t>}) & = - (y^{<t>} \log \widehat{y}^{<t>} + (1-y^{<t>}) \log (1-\widehat{y}^{<t>}))
\\ \ell(\widehat{y},y) & = \sim_{t=1}^{T_m} \ell^{<t>}(\widehat{y}^{<t>},y^{<t>})                                              
\end{align}
\end{subequations}

  
 \end{itemize}


 \subsubsection{Vanishing Gradient with RNNs}\label{sec_RNN_Vanishing}
 
 As we explained, RNN works on sequential data, and the idea is to predict new output not only based on the input data vector but also, other input vectors. Due to the recurrent structure in RNNs, it tends to suffer from long-term dependency to simplify this point let’s have an example, the following sentence \\
 \textit{Waleed Yousef who is Associate Professor at Helwan University and teaching Data Science courses and its dependencies \textbf{\underline{was}} got Ph.D. in Computer Engineering from GWU at 2006.}.

 In the previous example, to predict the word was is depending on long dependency to check if Waleed is singular or not to be consistent. Also, shows how some problems need the long-term dependencies handling.[Bengio et al.,1994]\cite{Bengio_ et_ al} showed that Basic RNNs has a problem in long-term dependency.  Another problem which may happen into basic Neural Networks is gradient exploding. One of the side-effects of gradient exploding is exponentially large gradient which causes our parameters to be so large. So, the Neural Networks parameters will have a server problem. Another fetal problem with Basic Neural Networks is overfitting problems [Zaremba et al., 2014]\cite{Zaremba_et_al}.
 
 So, to solve this learning problem [Hochreiter and Schmidhuber, 1997] introduced Long Short-Term Memory which helps to reduce the dependency problem using memory cell and forget gate.
\newpage
\subsection{Long Short Term Memory networks (LSTMs)}\label{sec_LSTM}


Long Short Term Memory networks – aka “LSTMs” – are a special type of RNN, capable of learning long-term dependencies. To solve the vanishing gradient problem for long-term dependencies, [Hochreiter and Schmidhuber, 1997]\cite{Hochreiter} suggested new cell architecture for RNN by adding Long Short Term Memory which significantly reduced the long-term dependency problem using memory cell and forget gate.

 LSTMs designed to help solving the long-term dependency problem and to hold information in memory for long periods of time. It also, use same RNNs sequential model but with adding some gating mechanism structure to every cell.

 Both Basic RNNs and LSTM have the form of a chain of repeating modules of neural network. The main difference is the structure of the Networks.
 
\begin{figure}[ht!] \includegraphics[width=\linewidth]{./Figures/Ch_2_Background/LSTM-SimpleRNN.png}
  \caption{The repeating module in a standard RNN contains a single layer.\cite{colah}}
  \label{fig:LSTM-SimpleRNN}
\end{figure}

In Basic RNNs it is very simple structure for every layer with simple output function~\ref{fig:LSTM-SimpleRNN}. But in LSTMs it has four interacting layers~\ref{fig:LSTM-cell-chaining}. 

%\begin{figure}[ht!] \includegraphics[width=\linewidth]{./Figures/Ch_2_Background/LSTM-cell-chaining.png}
  %\caption{The repeating module in an LSTM contains four interacting layers.\cite{colah}}\label{fig:LSTM-cell-chaining}
%\end{figure}

\input{./Figures/Ch_2_Background/Fig_LSTM_Main_Figure_3_Cells.tex}

\subsubsection{LSTM Gate Mechanism}

The main component of LSTM is the cell state; It allows the information to pass through along it unchanged. In figure xxx the top line show the information flow through the cell. The LSTM cell can add or remove information to the cell state using the Gating mechanism. 

Gates's idea is a methodology to manage the way how and which information pass or not. It controls information flow through the cell. It has three of these gates. They are consist of a sigmoid neural network layer~\ref{fig:LSTM-Cell-state} and a pointwise multiplication operation~\ref{fig:LSTM-gate}.

Sigmoid function output values between zero and one. If the value is one these means that everything should pass, while if the value is zero these means do not pass anything. So, the value output from the sigmoid function refers to the amount of each component should be passed.

%\begin{figure}[ht!]
%    \centering
%        \includegraphics[width=\textwidth]{./Figures/Ch_2_Background/LSTM-Cell-state.png}
%        \caption{LSTM top horizontal line working as the medium for information flow~\cite{colah}}
%        \label{fig:LSTM-Cell-state}
%      \end{figure}
      \begin{figure}[ht!]
    \centering
\input{./Figures/Ch_2_Background/Fig_LSTM_Cell_State.tex}
        \caption{LSTM top horizontal line working as the medium for information flow~\cite{colah}}
      \label{fig:LSTM-Cell-state}
      \end{figure}

      
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.2\textwidth]{./Figures/Ch_2_Background/LSTM-gate.png}
        \caption{Cell gate with sigmoid function and a pointwise multiplication operation~\cite{colah}}
        \label{fig:LSTM-gate}
\end{figure}

\newpage
\subsubsection{How LSTM Works?}

We have explained LSTM has three gates with some 

\begin{itemize}
  
\item \textbf{Forget Gate Layer} a Sigmoid layer~\ref{fig:LSTM-forget-gate} decides which information will be allowed to pass and which will not. It looks at $h_{t-1}$ and $x_t$, and calculate the output from Sigmoid function between zero and one. As explained if one \textit{everything should pass}, while if zero \textit{do not pass anything}. The value zero or one depends on the value of the cell state if it includes a gender type and we need to predict the pronouns so, it will pass else it will ride of this state.

%\begin{figure}[ht!]
%    \centering
%        \includegraphics[width=\textwidth]{./Figures/Ch_2_Background/LSTM-forget-gate.png}
%        \caption{LSTM sigmoid forget gate~\cite{colah}}
%        \label{fig:LSTM-forget-gate}
%\end{figure}

\begin{figure}[ht!]
    \centering
        \input{./Figures/Ch_2_Background/Fig_LSTM_forget_gate.tex}
        \caption{LSTM sigmoid forget gate~\cite{colah}}\label{fig:LSTM-forget-gate}
\end{figure}



\item \textbf{Input Gate Layer} is a combination between \textit{sigmoid layer} which works to decide which values we should be updated, and \textit{tanh layer} creates a new vector of the new information $\tilde{C_t}$ which should be stored for the next state~\ref{fig:LSTM-input-gate}. The previous combination controls the update state. This layer used when we have new input information. For example, We have a new subject named Elizabeth we need to store it for the next input. The next step is the pointwise multiplication and addition operations.

%\begin{figure}[ht!]
   % \centering
   %     \includegraphics[width=\textwidth]{./Figures/Ch_2_Background/LSTM-input-gate.png}
  %      \caption{LSTM Input gate a combination of Sigmoid and Tanh layers~\cite{colah}}
 %       \label{fig:LSTM-input-gate}
%\end{figure}
\begin{figure}[ht!]
    \centering
        \input{./Figures/Ch_2_Background/Fig_LSTM_Input_Gate.tex}
        \caption{LSTM Input gate a combination of Sigmoid and Tanh layers~\cite{colah}}
        \label{fig:LSTM-input-gate}
\end{figure}


\item \textbf{Multiplication and Addition operations} This step is to apply the actions recommended by the previous gates. This step is the actions applying the forget of the old information and add the new information, as we decided in the previous steps. Let's look into the upper line in~\ref{fig:LSTM-pointwise-operations} there are two operations, 
  \begin{enumerate}
  \item Multiplication Operation: This operation to apply the forget gate step by multiplying the old state $\tilde{C}_{t-1} $ by the $f_t$.
  \item Addition Operation: This operation will add the output from the previous multiplication with the new input information scaled by how much we need to update each state value $i_t * \tilde{C_t}$
    \end{enumerate}

%    \begin{figure}[ht!]
%    \centering %\includegraphics[width=\textwidth]{./Figures/Ch_2_Background/LSTM-pointwise-operations.png}
%        \caption{LSTM Multiplication and Addition Operation in LSTM~\cite{colah}}
%        \label{fig:LSTM-pointwise-operations}
%      \end{figure}


    \begin{figure}[ht!]
      \centering
      \input{./Figures/Ch_2_Background/Fig_LSTM_pointwise_operations.tex}
        \caption{LSTM Multiplication and Addition Operation in LSTM~\cite{colah}}
        \label{fig:LSTM-pointwise-operations}
      \end{figure}
      
      
    \item \textbf{Output Gate} This gate is a combination of \textit{sigmoid} layer and \textit{tanh} layer. \textit{Sigmoid} layer decides the information which should be output. Then the output of the  \textit{sigmoid} function will be multiplying with the output of the \textit{tanh} layer of the cell state. This \textit{tanh} will make the values between -1 and 1. The output of the multiplication of \textit{sigmoid} and \textit{tanh} will be the final output. In practice, this gate responsible for deciding which information should be the output. For example, if it saw a subject such as Elizabeth, it might want to output a verb to be relevant to her as a singular.

%\begin{figure}[ht!]
%    \centering \includegraphics[width=\textwidth]{./Figures/Ch_2_Background/LSTM-output-gate.png}
%        \caption{LSTM Multiplication and Addition Operation in LSTM~\cite{colah}}
%        \label{fig:LSTM-output-gate}
%      \end{figure}

      
\begin{figure}[ht!]
  \centering
  \input{./Figures/Ch_2_Background/Fig_LSTM_output_gate.tex}
        \caption{LSTM Multiplication and Addition Operation in LSTM~\cite{colah}}\label{fig:LSTM-output-gate}
      \end{figure}
      
    \end{itemize}

    
    We have explained the normal LSTM. Also, we need to mention that there are much research proposed different modifications of the normal LSTM type. We will not explain all the types, but we will give a small overview of one of these modifications named Gated Recurrent Unit (GRU) in the next part.
\newpage
\subsubsection{Gated Recurrent Units (GRUs)}

In RNN Gated recurrent units (GRUs) are a gating mechanism, introduced in 2014 by Kyunghyun Cho et al.~\cite{Cho_et_al}. It works to overcome the problem for long-term dependencies. It also aimed to solve the vanishing gradient problem from Basic RNNs.It proposed a new architecture~\ref{fig:GRU} similar than the LSTM but with some major variants as below,
\begin{itemize}
  
\item It combines the forget gate and input gates into a single gate named “update gate and reset gate.”
\item The GRU unit controls the flow of information without having to use a memory unit. It just exposes the full hidden content without any control.
\item It also merges the cell state and hidden state.
  
\end{itemize}
\begin{figure}[ht!]
  \centering
  \includegraphics[width=\textwidth]{./Figures/Ch_2_Background/GRU.png}
        \caption{GRU cell architecture~\cite{colah}}
        \label{fig:GRU}
      \end{figure}


The result of this modifications is GRUs are simpler and easier for modifications in the design. GRUs trains faster and in some case, it performs better than LSTMs on less training data mainly in language modeling. However, LSTMs has some benefits over GRUs in case longer sequences than GRUs in tasks requiring modeling long-distance relations. 


 
\subsubsection{BI-LSTM}\label{sec_bi-lstm}

BI-LSTM two LSTMs stacked on top of each other, It used to solve some problem where the information needs to be considered in both directions for LSTM. As the normal LSTM is working from left to right, the BI-LSTM adds the other directions into the learning information. Let's take a motivation example regarding why we need BI-LSTM?
\begin{itemize}
\item \textit{Harry is the king, and he will travel next week.}
\item \textit{The new book which makes the big sale named Harry Poter}.
\end{itemize}
Harry in the first example refers to a person, however, in the second example refers to the book. So, if we are working left to right, we will not get the type of word Harry in the second example.

The architecture in BI-LSTM is similar to what we discussed previous regarding Uni-LSTM. We can mention here that BI-LSTM is very slow compared to LSTM, and it needs much time in the training phase, but for example, As we will see later in our research it is impressive regarding the results and the effect in the language problems.
 % @@@ example about the weakness about RNN and tiddy example when we talk about Bi-LSTM 



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../master"
%%% End: