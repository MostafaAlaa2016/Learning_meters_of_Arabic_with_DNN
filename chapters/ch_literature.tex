\section{Literature Review}\label{Ch:Literature}

Poetry meter classification and detection have not addressed as a learning problem or similar our way for solving this problem. In this literature, we can see that they treat the problem mainly as deterministic. They are restricted by some static conditions and unable to build a scientific approach to address the problem.

%
\subsection{Deterministic (Algorithmic) Approach}\label{sec:Determ_Algor_Appr}


~\cite{Abuata2016RuleBasedAlgorithm} present the work most related to our topic, classifying Arabic poetry according to its meters. However, they have not addressed it as a \textit{learning problem}; they have designed a \textit{deterministic five-step algorithm} for analyzing and detecting meters. The first and most important step is to have the input text carrying full diacritics; this means that every single letter must carry a diacritic, explicitly. The next step is converting input text into \textit{Arud writing} using \textit{if-else} like rules. \textit{Arud writing} is a pronounced version of writing; where only pronounced sounds written. Then metrical scansion rules are applied to the \textit{Arud writing}, which leaves the input text as a sequence of zeros and ones. After that, each group of zeros and ones is defined as a \textit{tafa'il}, giving a sequence of \textit{tafa'il}. Finally, the input text classifies the closest meter to the \textit{tafa'il} sequence. 82.2\% is the classification accuracy on a relatively small sample, of 417 verses.

\cite{Alnagdawi2013FindingArabicPoemMeter} has taken a similar approach to the previous work, but it replaced the \textit{if-else} by \textit{regular expressions} templates. This approach formalized the scansions, Arud based on lingual rules relating to pronounced and silent rules, directly related to \textit{harakat} as context-free grammar. Only 75\% of128 verses were correctly classified. 

\cite{Kurt2012AlgorithmForDetectionAnalysis} have taken a similar approach but worked on detecting and analyzing the arud meters in Ottoman Language. They convert the text into a lingual form in which the meters appear. Their first step is converting Ottoman text transliterated to Latin Transcription alphabet (LTA). Subsequently, they feed the text to the algorithm which uses a database containing all Ottoman meters to compare the detected meter extracted from LTA to the closest meter found in the database which saved the meters.

Both~\cite{Abuata2016RuleBasedAlgorithm} and~\cite{Alnagdawi2013FindingArabicPoemMeter} have common problems:

\begin{enumerate}
\item \textbf{The size of the test data} which cannot measure the accuracy for any algorithms they have constructed because it is a very small dataset. In addition, a 75\% total accuracy of 128 verses is even worse.
\item \textbf{The step converting verses into ones and zeros pattern} is probabilistic; it also depends on the meaning, which is a source of randomness. Treating such a problem as a deterministic problem will not satisfy the case study. It results in many limitations, including obligating verses to have full diacritics on every single letter before conducting the classification. This is also the case with~\cite{Kurt2012AlgorithmForDetectionAnalysis} work: for their algorithm to work, the text must be transliterated into LTA.
\end{enumerate}

We can summarize the results difference between our work and the previous work in Table~\ref{Tab:Summary_Results}

\begin{table}[h]
\centering
\begin{tabular}{c c c}
\toprule
\textbf{Ref.}& \textbf{Accuracy}& \textbf{Test Size} \\
\midrule
\cite{Alnagdawi2013FindingArabicPoemMeter} & 75\% & 128\\
\cite{Abuata2016RuleBasedAlgorithm}& 82.2\% & 417\\
This article & 96.38\%& 150,000 \\
\bottomrule
\end{tabular}
\caption{Overall accuracy of this article compared to literature.}\label{Tab:Summary_Results}
\end{table}




%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../master"
%%% TeX-engine: xetex
%%% End:
